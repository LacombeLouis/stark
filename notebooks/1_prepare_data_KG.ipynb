{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, x):\n",
    "    # Calculate the number of rows per subset\n",
    "    total_rows = len(df)\n",
    "    subset_size = total_rows // x\n",
    "\n",
    "    # Create empty list to hold subsets\n",
    "    subsets = []\n",
    "\n",
    "    # Split the DataFrame into subsets\n",
    "    for i in range(x):\n",
    "        start_index = i * subset_size\n",
    "        end_index = (i + 1) * subset_size if i < x - 1 else total_rows\n",
    "        subset = df.iloc[start_index:end_index].reset_index(drop=True)\n",
    "        subsets.append(subset)\n",
    "\n",
    "    # Now subsets[i] contains the i-th subset\n",
    "    # You can access each subset like subsets[0], subsets[1], etc.\n",
    "\n",
    "    # Example usage: Print the first few rows of each subset\n",
    "    for i, subset in enumerate(subsets):\n",
    "        print(f\"Subset {i+1} - Rows: {len(subset)}\")\n",
    "        print(subset.head())\n",
    "        print()  # Separate subsets with a blank line\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../prime/raw/kg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all types to string\n",
    "df = df.astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes = df[[\"x_index\", \"x_type\", \"x_name\", \"x_source\"]]\n",
    "df_nodes = df_nodes.rename(columns={\"x_index\": \"y_index\", \"x_type\": \"y_type\", \"x_name\": \"y_name\", \"x_source\": \"y_source\"})\n",
    "\n",
    "# append the same columns with y_ prefix to df_nodes\n",
    "df_nodes = pd.concat([df_nodes, df_nodes[[\"y_index\", \"y_type\", \"y_name\", \"y_source\"]]], axis=0)\n",
    "\n",
    "df_nodes = df_nodes.rename(columns={\"y_index\": \"ID\", \"y_type\": \"type\", \"y_name\": \"name\", \"y_source\": \"source\"})\n",
    "\n",
    "print(\"Size of df_nodes before drop duplicates: \", df_nodes.shape[0])\n",
    "# keep unique rows of df_nodes\n",
    "df_nodes = df_nodes.drop_duplicates(ignore_index=False)\n",
    "print(\"Size of df_nodes after drop duplicates: \", df_nodes.shape[0])\n",
    "\n",
    "df_nodes['name'] = df_nodes['name'].str.replace(\"'\", \" \")\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = \"text-embedding-ada-002\"\n",
    "candidate_emb_path = osp.join(\"../data/embedding/\", 'candidate_emb_dict.pt')\n",
    "print(candidate_emb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if osp.exists(candidate_emb_path):\n",
    "    candidate_emb_dict = torch.load(candidate_emb_path)\n",
    "    print(f'Loaded candidate_emb_dict from {candidate_emb_path}!')\n",
    "else:\n",
    "    print(f'candidate_emb_dict not found in {candidate_emb_path}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_id = []\n",
    "list_emb = []\n",
    "for item in tqdm(candidate_emb_dict):\n",
    "    list_id.append(item)\n",
    "    list_emb.append(candidate_emb_dict[item].numpy().tolist()[0])\n",
    "\n",
    "len_emb = len(list_emb[0])\n",
    "print(len_emb)\n",
    "\n",
    "df_emb = pd.DataFrame(zip(list_id, list_emb), columns=[\"ID\", \"embedding\"])\n",
    "df_emb[\"ID\"] = df_emb[\"ID\"].astype(str)\n",
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_final = pd.merge(df_nodes, df_emb, on=\"ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datasets = split_dataset(df_nodes_final, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate(df_datasets):\n",
    "    item.to_csv(f\"../prime/new/kg_nodes_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = df[[\"relation\", \"display_relation\"]]\n",
    "\n",
    "# keep unique rows of df_nodes\n",
    "df_edges = df_edges.drop_duplicates(ignore_index=False)\n",
    "\n",
    "df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we want to use display relation as those are the true edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get node relation node list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relations = df[[\"x_index\", \"display_relation\", \"relation\", \"y_index\"]]\n",
    "df_relations[\"display_relation\"] = df_relations[\"display_relation\"].str.replace(\" \", \"_\")\n",
    "df_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relations[\"display_relation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datasets = split_dataset(df_relations, 10)\n",
    "\n",
    "for i, item in enumerate(df_datasets):\n",
    "    item.to_csv(f\"../prime/new/kg_relations_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stark-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
